{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from quant import quant, dequant\n",
    "\n",
    "model_name = 'facebook/opt-6.7b'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "a = torch.randn(4096, 4096)\n",
    "head_dim = 128\n",
    "num_heads = 32\n",
    "scaling = head_dim**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_act = torch.load('/raid/jwjeong/results/attn_activation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, num_heads, head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "soft_max_results = {}\n",
    "\n",
    "for layer, key in enumerate(collected_act):\n",
    "    cur_act = collected_act[key]\n",
    "    soft_max_results[key] = []\n",
    "    for i in range(len(cur_act)):\n",
    "        q_proj_test = model.model.decoder.layers[layer].self_attn.q_proj\n",
    "        k_proj_test = model.model.decoder.layers[layer].self_attn.k_proj\n",
    "        bsz, tgt_len, _ = cur_act[i].size()\n",
    "        with torch.no_grad():\n",
    "            query_states = q_proj_test(cur_act[i]) * scaling\n",
    "            key_states = _shape(k_proj_test(cur_act[i]), -1, bsz)\n",
    "            proj_shape = (bsz * num_heads, -1, head_dim)\n",
    "            query_states = _shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
    "            key_states = key_states.view(*proj_shape)\n",
    "            src_len = key_states.size(1)\n",
    "\n",
    "\n",
    "            attention_mask = torch.zeros(bsz, 1, tgt_len, src_len).to(model.device)\n",
    "            min_val = torch.finfo(model.dtype).min\n",
    "            for i in range(tgt_len):\n",
    "                for j in range(src_len):\n",
    "                    if i < j:\n",
    "                        attention_mask[0][0][i][j] = min_val\n",
    "\n",
    "            attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "            \n",
    "            attn_weights = attn_weights.view(bsz, num_heads, tgt_len, src_len) + attention_mask\n",
    "            attn_weights = torch.max(\n",
    "                attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min, device=attn_weights.device)\n",
    "            )\n",
    "            attn_weights = attn_weights.view(bsz * num_heads, tgt_len, src_len)\n",
    "            if attn_weights.dtype == torch.float16:\n",
    "                attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)\n",
    "            else:\n",
    "                attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
    "            \n",
    "            soft_max_results[key].append(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(soft_max_results, 'softmax_results.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
