{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwjeong/anaconda3/envs/autogptq/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n"
     ]
    }
   ],
   "source": [
    "# 3.1s\n",
    "from utils import build_model_and_tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from quant import quant, dequant, quant_unpack, dequant_unpack\n",
    "import torch.nn as nn\n",
    "from transformers.pytorch_utils import Conv1D\n",
    "import functools\n",
    "from functools import partial\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'facebook/opt-6.7b'\n",
    "device = \"cuda:1\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "testenc = tokenizer(\"\\n\\n\".join(dataset[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 8\n",
    "gs = 128\n",
    "scale, zero, qs = quant(bits, gs, model)\n",
    "q_x = dequant(scale, zero, qs, gs, bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = next(model.parameters()).device # next는 객체의 __next__ 호출, 다음 iter를 부름?\n",
    "act_scales = {}\n",
    "scaled_act_max = {}\n",
    "scaled_act_min = {}\n",
    "scaled_act_sum = {}\n",
    "scaled_act_absum = {}\n",
    "scaled_act_numel = {}\n",
    "\n",
    "def stat_tensor(name, tensor):\n",
    "    hidden_dim = tensor.shape[-1]\n",
    "    tensor = tensor.view(-1, hidden_dim).detach()\n",
    "    act_shape = tensor.shape\n",
    "    for i in range(len(scale[name])):\n",
    "        temp = scale[name][i].expand(gs, -1).T.flatten().expand(act_shape[0], -1).to(device)\n",
    "        scaled_act = (tensor * temp)\n",
    "        if name in scaled_act_max:\n",
    "            scaled_act_max[name] = scaled_act.max() if scaled_act_max[name] < scaled_act.max() else scaled_act_max[name]\n",
    "            scaled_act_min[name] = scaled_act.min() if scaled_act_min[name] > scaled_act.min() else scaled_act_min[name]\n",
    "            scaled_act_sum[name] += scaled_act.sum()\n",
    "            scaled_act_absum[name] += torch.abs(scaled_act).sum()\n",
    "            scaled_act_numel[name] += torch.numel(scaled_act)\n",
    "        else:\n",
    "            scaled_act_max[name] = scaled_act.max()\n",
    "            scaled_act_min[name] = scaled_act.min()\n",
    "            scaled_act_sum[name] = scaled_act.sum()\n",
    "            scaled_act_absum[name] = torch.abs(scaled_act).sum()\n",
    "            scaled_act_numel[name] = torch.numel(scaled_act)\n",
    "\n",
    "\n",
    "def stat_input_hook(m, x, y, name):\n",
    "    if isinstance(x, tuple):\n",
    "        x = x[0]\n",
    "    stat_tensor(name, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "for name, m in model.named_modules():\n",
    "    if isinstance(m, nn.Linear) | isinstance(m, Conv1D):\n",
    "        hooks.append(\n",
    "            m.register_forward_hook(\n",
    "                functools.partial(stat_input_hook, name=name))\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset_list = []\n",
    "for ii in range(len(dataset)):\n",
    "    if dataset[ii]['text'] != '':\n",
    "        dataset_list.append(dataset[ii])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:21<00:00,  5.32s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 4\n",
    "seq_len = 64\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    input_ids = tokenizer(dataset_list[i][\"text\"], return_tensors=\"pt\",\n",
    "                            max_length=seq_len, truncation=True).input_ids.to(device)\n",
    "    model(input_ids)\n",
    "\n",
    "for h in hooks:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_act_avg = {}\n",
    "scaled_act_absavg = {}\n",
    "scaled_act_minmax = {}\n",
    "for key in scaled_act_max:\n",
    "    scaled_act_avg[key] = scaled_act_sum[key] / scaled_act_numel[key]\n",
    "    scaled_act_absavg[key] = scaled_act_absum[key] / scaled_act_numel[key]\n",
    "    scaled_act_minmax[key] = scaled_act_max[key] - scaled_act_min[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.decoder.layers.0.self_attn.q_proj': tensor(0.0049, device='cuda:1'),\n",
       " 'model.decoder.layers.0.self_attn.k_proj': tensor(0.0081, device='cuda:1'),\n",
       " 'model.decoder.layers.0.self_attn.v_proj': tensor(0.0033, device='cuda:1'),\n",
       " 'model.decoder.layers.0.self_attn.out_proj': tensor(0.0010, device='cuda:1'),\n",
       " 'model.decoder.layers.0.fc1': tensor(0.0471, device='cuda:1'),\n",
       " 'model.decoder.layers.0.fc2': tensor(0.0019, device='cuda:1'),\n",
       " 'model.decoder.layers.1.self_attn.q_proj': tensor(0.0355, device='cuda:1'),\n",
       " 'model.decoder.layers.1.self_attn.k_proj': tensor(0.0365, device='cuda:1'),\n",
       " 'model.decoder.layers.1.self_attn.v_proj': tensor(0.0203, device='cuda:1'),\n",
       " 'model.decoder.layers.1.self_attn.out_proj': tensor(0.0003, device='cuda:1'),\n",
       " 'model.decoder.layers.1.fc1': tensor(0.0452, device='cuda:1'),\n",
       " 'model.decoder.layers.1.fc2': tensor(0.0017, device='cuda:1'),\n",
       " 'model.decoder.layers.2.self_attn.q_proj': tensor(0.0405, device='cuda:1'),\n",
       " 'model.decoder.layers.2.self_attn.k_proj': tensor(0.0336, device='cuda:1'),\n",
       " 'model.decoder.layers.2.self_attn.v_proj': tensor(0.0223, device='cuda:1'),\n",
       " 'model.decoder.layers.2.self_attn.out_proj': tensor(0.0003, device='cuda:1'),\n",
       " 'model.decoder.layers.2.fc1': tensor(0.0438, device='cuda:1'),\n",
       " 'model.decoder.layers.2.fc2': tensor(0.0013, device='cuda:1'),\n",
       " 'model.decoder.layers.3.self_attn.q_proj': tensor(0.0307, device='cuda:1'),\n",
       " 'model.decoder.layers.3.self_attn.k_proj': tensor(0.0296, device='cuda:1'),\n",
       " 'model.decoder.layers.3.self_attn.v_proj': tensor(0.0242, device='cuda:1'),\n",
       " 'model.decoder.layers.3.self_attn.out_proj': tensor(0.0004, device='cuda:1'),\n",
       " 'model.decoder.layers.3.fc1': tensor(0.0424, device='cuda:1'),\n",
       " 'model.decoder.layers.3.fc2': tensor(0.0014, device='cuda:1'),\n",
       " 'model.decoder.layers.4.self_attn.q_proj': tensor(0.0291, device='cuda:1'),\n",
       " 'model.decoder.layers.4.self_attn.k_proj': tensor(0.0266, device='cuda:1'),\n",
       " 'model.decoder.layers.4.self_attn.v_proj': tensor(0.0252, device='cuda:1'),\n",
       " 'model.decoder.layers.4.self_attn.out_proj': tensor(0.0005, device='cuda:1'),\n",
       " 'model.decoder.layers.4.fc1': tensor(0.0446, device='cuda:1'),\n",
       " 'model.decoder.layers.4.fc2': tensor(0.0021, device='cuda:1'),\n",
       " 'model.decoder.layers.5.self_attn.q_proj': tensor(0.0224, device='cuda:1'),\n",
       " 'model.decoder.layers.5.self_attn.k_proj': tensor(0.0257, device='cuda:1'),\n",
       " 'model.decoder.layers.5.self_attn.v_proj': tensor(0.0228, device='cuda:1'),\n",
       " 'model.decoder.layers.5.self_attn.out_proj': tensor(0.0004, device='cuda:1'),\n",
       " 'model.decoder.layers.5.fc1': tensor(0.0404, device='cuda:1'),\n",
       " 'model.decoder.layers.5.fc2': tensor(0.0018, device='cuda:1'),\n",
       " 'model.decoder.layers.6.self_attn.q_proj': tensor(0.0272, device='cuda:1'),\n",
       " 'model.decoder.layers.6.self_attn.k_proj': tensor(0.0272, device='cuda:1'),\n",
       " 'model.decoder.layers.6.self_attn.v_proj': tensor(0.0265, device='cuda:1'),\n",
       " 'model.decoder.layers.6.self_attn.out_proj': tensor(0.0007, device='cuda:1'),\n",
       " 'model.decoder.layers.6.fc1': tensor(0.0490, device='cuda:1'),\n",
       " 'model.decoder.layers.6.fc2': tensor(0.0016, device='cuda:1'),\n",
       " 'model.decoder.layers.7.self_attn.q_proj': tensor(0.0418, device='cuda:1'),\n",
       " 'model.decoder.layers.7.self_attn.k_proj': tensor(0.0403, device='cuda:1'),\n",
       " 'model.decoder.layers.7.self_attn.v_proj': tensor(0.0339, device='cuda:1'),\n",
       " 'model.decoder.layers.7.self_attn.out_proj': tensor(0.0006, device='cuda:1'),\n",
       " 'model.decoder.layers.7.fc1': tensor(0.0410, device='cuda:1'),\n",
       " 'model.decoder.layers.7.fc2': tensor(0.0020, device='cuda:1'),\n",
       " 'model.decoder.layers.8.self_attn.q_proj': tensor(0.0503, device='cuda:1'),\n",
       " 'model.decoder.layers.8.self_attn.k_proj': tensor(0.0440, device='cuda:1'),\n",
       " 'model.decoder.layers.8.self_attn.v_proj': tensor(0.0254, device='cuda:1'),\n",
       " 'model.decoder.layers.8.self_attn.out_proj': tensor(0.0009, device='cuda:1'),\n",
       " 'model.decoder.layers.8.fc1': tensor(0.0439, device='cuda:1'),\n",
       " 'model.decoder.layers.8.fc2': tensor(0.0024, device='cuda:1'),\n",
       " 'model.decoder.layers.9.self_attn.q_proj': tensor(0.0436, device='cuda:1'),\n",
       " 'model.decoder.layers.9.self_attn.k_proj': tensor(0.0379, device='cuda:1'),\n",
       " 'model.decoder.layers.9.self_attn.v_proj': tensor(0.0259, device='cuda:1'),\n",
       " 'model.decoder.layers.9.self_attn.out_proj': tensor(0.0008, device='cuda:1'),\n",
       " 'model.decoder.layers.9.fc1': tensor(0.0447, device='cuda:1'),\n",
       " 'model.decoder.layers.9.fc2': tensor(0.0017, device='cuda:1'),\n",
       " 'model.decoder.layers.10.self_attn.q_proj': tensor(0.0634, device='cuda:1'),\n",
       " 'model.decoder.layers.10.self_attn.k_proj': tensor(0.0574, device='cuda:1'),\n",
       " 'model.decoder.layers.10.self_attn.v_proj': tensor(0.0314, device='cuda:1'),\n",
       " 'model.decoder.layers.10.self_attn.out_proj': tensor(0.0008, device='cuda:1'),\n",
       " 'model.decoder.layers.10.fc1': tensor(0.0394, device='cuda:1'),\n",
       " 'model.decoder.layers.10.fc2': tensor(0.0020, device='cuda:1'),\n",
       " 'model.decoder.layers.11.self_attn.q_proj': tensor(0.0520, device='cuda:1'),\n",
       " 'model.decoder.layers.11.self_attn.k_proj': tensor(0.0425, device='cuda:1'),\n",
       " 'model.decoder.layers.11.self_attn.v_proj': tensor(0.0278, device='cuda:1'),\n",
       " 'model.decoder.layers.11.self_attn.out_proj': tensor(0.0010, device='cuda:1'),\n",
       " 'model.decoder.layers.11.fc1': tensor(0.0470, device='cuda:1'),\n",
       " 'model.decoder.layers.11.fc2': tensor(0.0025, device='cuda:1'),\n",
       " 'model.decoder.layers.12.self_attn.q_proj': tensor(0.0482, device='cuda:1'),\n",
       " 'model.decoder.layers.12.self_attn.k_proj': tensor(0.0484, device='cuda:1'),\n",
       " 'model.decoder.layers.12.self_attn.v_proj': tensor(0.0267, device='cuda:1'),\n",
       " 'model.decoder.layers.12.self_attn.out_proj': tensor(0.0013, device='cuda:1'),\n",
       " 'model.decoder.layers.12.fc1': tensor(0.0360, device='cuda:1'),\n",
       " 'model.decoder.layers.12.fc2': tensor(0.0029, device='cuda:1'),\n",
       " 'model.decoder.layers.13.self_attn.q_proj': tensor(0.0479, device='cuda:1'),\n",
       " 'model.decoder.layers.13.self_attn.k_proj': tensor(0.0444, device='cuda:1'),\n",
       " 'model.decoder.layers.13.self_attn.v_proj': tensor(0.0291, device='cuda:1'),\n",
       " 'model.decoder.layers.13.self_attn.out_proj': tensor(0.0012, device='cuda:1'),\n",
       " 'model.decoder.layers.13.fc1': tensor(0.0441, device='cuda:1'),\n",
       " 'model.decoder.layers.13.fc2': tensor(0.0024, device='cuda:1'),\n",
       " 'model.decoder.layers.14.self_attn.q_proj': tensor(0.0502, device='cuda:1'),\n",
       " 'model.decoder.layers.14.self_attn.k_proj': tensor(0.0513, device='cuda:1'),\n",
       " 'model.decoder.layers.14.self_attn.v_proj': tensor(0.0260, device='cuda:1'),\n",
       " 'model.decoder.layers.14.self_attn.out_proj': tensor(0.0013, device='cuda:1'),\n",
       " 'model.decoder.layers.14.fc1': tensor(0.0389, device='cuda:1'),\n",
       " 'model.decoder.layers.14.fc2': tensor(0.0024, device='cuda:1'),\n",
       " 'model.decoder.layers.15.self_attn.q_proj': tensor(0.0369, device='cuda:1'),\n",
       " 'model.decoder.layers.15.self_attn.k_proj': tensor(0.0322, device='cuda:1'),\n",
       " 'model.decoder.layers.15.self_attn.v_proj': tensor(0.0306, device='cuda:1'),\n",
       " 'model.decoder.layers.15.self_attn.out_proj': tensor(0.0016, device='cuda:1'),\n",
       " 'model.decoder.layers.15.fc1': tensor(0.0401, device='cuda:1'),\n",
       " 'model.decoder.layers.15.fc2': tensor(0.0034, device='cuda:1'),\n",
       " 'model.decoder.layers.16.self_attn.q_proj': tensor(0.0422, device='cuda:1'),\n",
       " 'model.decoder.layers.16.self_attn.k_proj': tensor(0.0393, device='cuda:1'),\n",
       " 'model.decoder.layers.16.self_attn.v_proj': tensor(0.0319, device='cuda:1'),\n",
       " 'model.decoder.layers.16.self_attn.out_proj': tensor(0.0020, device='cuda:1'),\n",
       " 'model.decoder.layers.16.fc1': tensor(0.0432, device='cuda:1'),\n",
       " 'model.decoder.layers.16.fc2': tensor(0.0030, device='cuda:1'),\n",
       " 'model.decoder.layers.17.self_attn.q_proj': tensor(0.0433, device='cuda:1'),\n",
       " 'model.decoder.layers.17.self_attn.k_proj': tensor(0.0386, device='cuda:1'),\n",
       " 'model.decoder.layers.17.self_attn.v_proj': tensor(0.0275, device='cuda:1'),\n",
       " 'model.decoder.layers.17.self_attn.out_proj': tensor(0.0021, device='cuda:1'),\n",
       " 'model.decoder.layers.17.fc1': tensor(0.0387, device='cuda:1'),\n",
       " 'model.decoder.layers.17.fc2': tensor(0.0041, device='cuda:1'),\n",
       " 'model.decoder.layers.18.self_attn.q_proj': tensor(0.0418, device='cuda:1'),\n",
       " 'model.decoder.layers.18.self_attn.k_proj': tensor(0.0365, device='cuda:1'),\n",
       " 'model.decoder.layers.18.self_attn.v_proj': tensor(0.0336, device='cuda:1'),\n",
       " 'model.decoder.layers.18.self_attn.out_proj': tensor(0.0021, device='cuda:1'),\n",
       " 'model.decoder.layers.18.fc1': tensor(0.0437, device='cuda:1'),\n",
       " 'model.decoder.layers.18.fc2': tensor(0.0034, device='cuda:1'),\n",
       " 'model.decoder.layers.19.self_attn.q_proj': tensor(0.0336, device='cuda:1'),\n",
       " 'model.decoder.layers.19.self_attn.k_proj': tensor(0.0358, device='cuda:1'),\n",
       " 'model.decoder.layers.19.self_attn.v_proj': tensor(0.0316, device='cuda:1'),\n",
       " 'model.decoder.layers.19.self_attn.out_proj': tensor(0.0022, device='cuda:1'),\n",
       " 'model.decoder.layers.19.fc1': tensor(0.0394, device='cuda:1'),\n",
       " 'model.decoder.layers.19.fc2': tensor(0.0046, device='cuda:1'),\n",
       " 'model.decoder.layers.20.self_attn.q_proj': tensor(0.0398, device='cuda:1'),\n",
       " 'model.decoder.layers.20.self_attn.k_proj': tensor(0.0368, device='cuda:1'),\n",
       " 'model.decoder.layers.20.self_attn.v_proj': tensor(0.0287, device='cuda:1'),\n",
       " 'model.decoder.layers.20.self_attn.out_proj': tensor(0.0034, device='cuda:1'),\n",
       " 'model.decoder.layers.20.fc1': tensor(0.0419, device='cuda:1'),\n",
       " 'model.decoder.layers.20.fc2': tensor(0.0065, device='cuda:1'),\n",
       " 'model.decoder.layers.21.self_attn.q_proj': tensor(0.0342, device='cuda:1'),\n",
       " 'model.decoder.layers.21.self_attn.k_proj': tensor(0.0348, device='cuda:1'),\n",
       " 'model.decoder.layers.21.self_attn.v_proj': tensor(0.0309, device='cuda:1'),\n",
       " 'model.decoder.layers.21.self_attn.out_proj': tensor(0.0021, device='cuda:1'),\n",
       " 'model.decoder.layers.21.fc1': tensor(0.0392, device='cuda:1'),\n",
       " 'model.decoder.layers.21.fc2': tensor(0.0076, device='cuda:1'),\n",
       " 'model.decoder.layers.22.self_attn.q_proj': tensor(0.0323, device='cuda:1'),\n",
       " 'model.decoder.layers.22.self_attn.k_proj': tensor(0.0295, device='cuda:1'),\n",
       " 'model.decoder.layers.22.self_attn.v_proj': tensor(0.0271, device='cuda:1'),\n",
       " 'model.decoder.layers.22.self_attn.out_proj': tensor(0.0045, device='cuda:1'),\n",
       " 'model.decoder.layers.22.fc1': tensor(0.0425, device='cuda:1'),\n",
       " 'model.decoder.layers.22.fc2': tensor(0.0051, device='cuda:1'),\n",
       " 'model.decoder.layers.23.self_attn.q_proj': tensor(0.0318, device='cuda:1'),\n",
       " 'model.decoder.layers.23.self_attn.k_proj': tensor(0.0289, device='cuda:1'),\n",
       " 'model.decoder.layers.23.self_attn.v_proj': tensor(0.0311, device='cuda:1'),\n",
       " 'model.decoder.layers.23.self_attn.out_proj': tensor(0.0036, device='cuda:1'),\n",
       " 'model.decoder.layers.23.fc1': tensor(0.0403, device='cuda:1'),\n",
       " 'model.decoder.layers.23.fc2': tensor(0.0072, device='cuda:1'),\n",
       " 'model.decoder.layers.24.self_attn.q_proj': tensor(0.0278, device='cuda:1'),\n",
       " 'model.decoder.layers.24.self_attn.k_proj': tensor(0.0244, device='cuda:1'),\n",
       " 'model.decoder.layers.24.self_attn.v_proj': tensor(0.0337, device='cuda:1'),\n",
       " 'model.decoder.layers.24.self_attn.out_proj': tensor(0.0042, device='cuda:1'),\n",
       " 'model.decoder.layers.24.fc1': tensor(0.0411, device='cuda:1'),\n",
       " 'model.decoder.layers.24.fc2': tensor(0.0088, device='cuda:1'),\n",
       " 'model.decoder.layers.25.self_attn.q_proj': tensor(0.0304, device='cuda:1'),\n",
       " 'model.decoder.layers.25.self_attn.k_proj': tensor(0.0277, device='cuda:1'),\n",
       " 'model.decoder.layers.25.self_attn.v_proj': tensor(0.0353, device='cuda:1'),\n",
       " 'model.decoder.layers.25.self_attn.out_proj': tensor(0.0045, device='cuda:1'),\n",
       " 'model.decoder.layers.25.fc1': tensor(0.0375, device='cuda:1'),\n",
       " 'model.decoder.layers.25.fc2': tensor(0.0101, device='cuda:1'),\n",
       " 'model.decoder.layers.26.self_attn.q_proj': tensor(0.0257, device='cuda:1'),\n",
       " 'model.decoder.layers.26.self_attn.k_proj': tensor(0.0255, device='cuda:1'),\n",
       " 'model.decoder.layers.26.self_attn.v_proj': tensor(0.0311, device='cuda:1'),\n",
       " 'model.decoder.layers.26.self_attn.out_proj': tensor(0.0056, device='cuda:1'),\n",
       " 'model.decoder.layers.26.fc1': tensor(0.0389, device='cuda:1'),\n",
       " 'model.decoder.layers.26.fc2': tensor(0.0089, device='cuda:1'),\n",
       " 'model.decoder.layers.27.self_attn.q_proj': tensor(0.0284, device='cuda:1'),\n",
       " 'model.decoder.layers.27.self_attn.k_proj': tensor(0.0278, device='cuda:1'),\n",
       " 'model.decoder.layers.27.self_attn.v_proj': tensor(0.0372, device='cuda:1'),\n",
       " 'model.decoder.layers.27.self_attn.out_proj': tensor(0.0047, device='cuda:1'),\n",
       " 'model.decoder.layers.27.fc1': tensor(0.0495, device='cuda:1'),\n",
       " 'model.decoder.layers.27.fc2': tensor(0.0091, device='cuda:1'),\n",
       " 'model.decoder.layers.28.self_attn.q_proj': tensor(0.0309, device='cuda:1'),\n",
       " 'model.decoder.layers.28.self_attn.k_proj': tensor(0.0314, device='cuda:1'),\n",
       " 'model.decoder.layers.28.self_attn.v_proj': tensor(0.0408, device='cuda:1'),\n",
       " 'model.decoder.layers.28.self_attn.out_proj': tensor(0.0057, device='cuda:1'),\n",
       " 'model.decoder.layers.28.fc1': tensor(0.0385, device='cuda:1'),\n",
       " 'model.decoder.layers.28.fc2': tensor(0.0073, device='cuda:1'),\n",
       " 'model.decoder.layers.29.self_attn.q_proj': tensor(0.0309, device='cuda:1'),\n",
       " 'model.decoder.layers.29.self_attn.k_proj': tensor(0.0335, device='cuda:1'),\n",
       " 'model.decoder.layers.29.self_attn.v_proj': tensor(0.0395, device='cuda:1'),\n",
       " 'model.decoder.layers.29.self_attn.out_proj': tensor(0.0050, device='cuda:1'),\n",
       " 'model.decoder.layers.29.fc1': tensor(0.0432, device='cuda:1'),\n",
       " 'model.decoder.layers.29.fc2': tensor(0.0085, device='cuda:1'),\n",
       " 'model.decoder.layers.30.self_attn.q_proj': tensor(0.0374, device='cuda:1'),\n",
       " 'model.decoder.layers.30.self_attn.k_proj': tensor(0.0339, device='cuda:1'),\n",
       " 'model.decoder.layers.30.self_attn.v_proj': tensor(0.0411, device='cuda:1'),\n",
       " 'model.decoder.layers.30.self_attn.out_proj': tensor(0.0056, device='cuda:1'),\n",
       " 'model.decoder.layers.30.fc1': tensor(0.0413, device='cuda:1'),\n",
       " 'model.decoder.layers.30.fc2': tensor(0.0067, device='cuda:1'),\n",
       " 'model.decoder.layers.31.self_attn.q_proj': tensor(0.0383, device='cuda:1'),\n",
       " 'model.decoder.layers.31.self_attn.k_proj': tensor(0.0341, device='cuda:1'),\n",
       " 'model.decoder.layers.31.self_attn.v_proj': tensor(0.0499, device='cuda:1'),\n",
       " 'model.decoder.layers.31.self_attn.out_proj': tensor(0.0060, device='cuda:1'),\n",
       " 'model.decoder.layers.31.fc1': tensor(0.0473, device='cuda:1'),\n",
       " 'model.decoder.layers.31.fc2': tensor(0.0129, device='cuda:1'),\n",
       " 'lm_head': tensor(0.0351, device='cuda:1')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(scaled_act_max, '/raid/jwjeong/results/scaled_act_max_opt.pt')\n",
    "torch.save(scaled_act_min, '/raid/jwjeong/results/scaled_act_min_opt.pt')\n",
    "torch.save(scaled_act_minmax, '/raid/jwjeong/results/scaled_act_minmax_opt.pt')\n",
    "torch.save(scaled_act_avg, '/raid/jwjeong/results/scaled_act_avg_opt.pt')\n",
    "torch.save(scaled_act_absavg, '/raid/jwjeong/results/scaled_act_absavg_opt.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
