{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwjeong/anaconda3/envs/autogptq/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from quant import quant, dequant\n",
    "\n",
    "model_name = 'facebook/opt-125m'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quant import quant, dequant\n",
    "\n",
    "bits = 8\n",
    "gs = 128\n",
    "scale, zero, qs = quant(bits, gs, model)\n",
    "q_x = dequant(scale, zero, qs, gs, bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in q_x.keys():\n",
    "    if key.split('.')[-1] != 'lm_head':\n",
    "        weight = key+'.weight'\n",
    "        model.state_dict()[weight][:] = q_x[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del q_x, scale, zero, qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "hidden_dim = model.config.hidden_size\n",
    "num_heads = model.config.num_attention_heads\n",
    "head_dim = hidden_dim // num_heads\n",
    "scaling = head_dim**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_act = torch.load('collected_act/attn_input_act_opt_125m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, num_heads, head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "soft_max_results = {}\n",
    "\n",
    "for layer, key in enumerate(collected_act):\n",
    "    cur_act = collected_act[key]\n",
    "    soft_max_results[key] = []\n",
    "    for i in range(len(cur_act)):\n",
    "        q_proj_test = model.model.decoder.layers[layer].self_attn.q_proj\n",
    "        k_proj_test = model.model.decoder.layers[layer].self_attn.k_proj\n",
    "        bsz, tgt_len, _ = cur_act[i].size()\n",
    "        with torch.no_grad():\n",
    "            query_states = q_proj_test(cur_act[i]) * scaling\n",
    "            key_states = _shape(k_proj_test(cur_act[i]), -1, bsz)\n",
    "            proj_shape = (bsz * num_heads, -1, head_dim)\n",
    "            query_states = _shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
    "            key_states = key_states.view(*proj_shape)\n",
    "            src_len = key_states.size(1)\n",
    "\n",
    "\n",
    "            attention_mask = torch.zeros(bsz, 1, tgt_len, src_len).to(model.device)\n",
    "            min_val = torch.finfo(model.dtype).min\n",
    "            for i in range(tgt_len):\n",
    "                for j in range(src_len):\n",
    "                    if i < j:\n",
    "                        attention_mask[0][0][i][j] = min_val\n",
    "\n",
    "            attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
    "            \n",
    "            attn_weights = attn_weights.view(bsz, num_heads, tgt_len, src_len) + attention_mask\n",
    "            attn_weights = torch.max(\n",
    "                attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min, device=attn_weights.device)\n",
    "            )\n",
    "            attn_weights = attn_weights.view(bsz * num_heads, tgt_len, src_len)\n",
    "            if attn_weights.dtype == torch.float16:\n",
    "                attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)\n",
    "            else:\n",
    "                attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
    "            \n",
    "            soft_max_results[key].append(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(soft_max_results, 'softmax_res/opt-125m-q8-128gs.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
